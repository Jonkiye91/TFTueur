# EPIC 1 ‚Äî Ingestion & Sch√©ma des donn√©es (ETL Polars)

**Objectif global :**  
Mettre en place une cha√Æne d‚Äôimportation de donn√©es TFT fiable et reproductible, qui lit les fichiers bruts, v√©rifie leur structure, les normalise (patch, stage, round), puis les stocke dans un format optimis√© pour les futures √©tapes de Machine Learning.

---

## üéØ TFT-ING-1 ‚Äî D√©finir sch√©ma brut & contrat de donn√©es (SP: 3)

**Description :**  
- Analyser les fichiers bruts (JSON, CSV ou autre) provenant de l‚ÄôAPI ou d‚Äôexports locaux.  
- Identifier tous les champs disponibles pour **les parties**, **les rounds**, **les shops** et **les joueurs**.  
- D√©finir un **contrat de donn√©es** : types attendus, contraintes (ex. `match_id` unique, `round` ‚â• 1), champs obligatoires vs optionnels.  
- Pr√©parer un document de r√©f√©rence qui servira √† toutes les √©tapes suivantes pour √©viter les incoh√©rences.  

**Pourquoi :**  
- Sans sch√©ma clair, les √©tapes suivantes risquent de casser √† cause de donn√©es manquantes ou mal typ√©es.  
- Le contrat de donn√©es permettra aussi d‚Äôajouter facilement de nouvelles sources √† l‚Äôavenir.  

**Comment :**  
1. Lire un √©chantillon de fichiers bruts.  
2. Lister tous les champs et types d√©tect√©s.  
3. D√©finir un dictionnaire `{champ: type, contraintes, description}`.  
4. Sauvegarder en Markdown (`schema.md`) et g√©n√©rer un exemple valide (`examples/sample.json`).  

**Crit√®res d‚Äôacceptation :**  
- Document complet avec tous les champs, types, contraintes et explications.  
- Exemple de fichier valide fourni.  
- Tous les champs critiques marqu√©s comme obligatoires.  

**Livrables :**  
- `docs/schema.md`  
- `examples/sample.json`  

**D√©pendances :** ‚Äî  

---

## üéØ TFT-ING-2 ‚Äî Lecteur Polars + validation de sch√©ma (SP: 5)

**Description :**  
- √âcrire un script Python utilisant **Polars** pour charger les donn√©es brutes.  
- Ajouter une validation automatique du sch√©ma (ex. via **pydantic** ou **pandera**).  
- Les fichiers qui ne respectent pas le contrat doivent √™tre rejet√©s avec un log clair expliquant le probl√®me.  

**Pourquoi :**  
- Assurer que toutes les donn√©es utilis√©es plus tard soient propres et coh√©rentes.  
- Gagner du temps en d√©tectant les anomalies d√®s l‚Äôimport.  

**Comment :**  
1. Lire les fichiers avec `pl.read_json()` ou `pl.read_parquet()` selon le format.  
2. Passer chaque DataFrame dans un validateur qui v√©rifie types et contraintes.  
3. √âcrire un log listant les fichiers invalides et la raison.  

**Crit√®res d‚Äôacceptation :**  
- Un fichier valide passe sans erreur.  
- Un fichier invalide est rejet√© avec un message explicite (ex. `"champ hp manquant"`).  
- Tests unitaires sur 3 cas : valide, champ manquant, type incorrect.  

**Livrables :**  
- `etl/load.py` (fonction `load_and_validate(path)` qui retourne un DataFrame Polars propre)  
- `tests/test_load.py`  

**D√©pendances :** TFT-ING-1  

---

## üéØ TFT-ING-3 ‚Äî Normalisation par patch/stage/round (SP: 5)

**Description :**  
- Ajouter dans le DataFrame des colonnes d√©riv√©es normalis√©es :  
  - **`patch`** : version exacte (ex. `"14.15"`), extraite de la date ou du champ version.  
  - **`stage`** : ex. `"3-2"` (stage 3 round 2).  
  - **`round_idx`** : num√©ro s√©quentiel global du round (commence √† 1 au d√©but de la partie).  
- G√©rer les fuseaux horaires si les timestamps sont utilis√©s.  

**Pourquoi :**  
- Le patch est n√©cessaire pour entra√Æner des mod√®les qui respectent la m√©ta.  
- Les stages/rounds sont essentiels pour comprendre le tempo de la partie.  
- `round_idx` est utile pour traiter la partie comme une s√©quence.  

**Comment :**  
1. √âcrire une fonction `normalize_round_info(df)` qui :  
   - lit les champs bruts (timestamp, round label, etc.)  
   - en d√©duit `patch`, `stage`, `round_idx`.  
2. Ajouter tests unitaires pour 3 exemples de parties.  

**Crit√®res d‚Äôacceptation :**  
- Tous les rounds ont un `stage` et un `round_idx` corrects.  
- Aucun patch vide ou incorrect.  

**Livrables :**  
- `etl/normalize.py`  
- `tests/test_normalize.py`  

**D√©pendances :** TFT-ING-2  

---

## üéØ TFT-ING-4 ‚Äî Stockage colonne (Parquet) + partitionnement (SP: 5)

**Description :**  
- Sauvegarder les donn√©es propres dans un format **Parquet** (stockage en colonnes).  
- Partitionner par `patch` et par `date` pour faciliter les filtrages ult√©rieurs.  
- V√©rifier que la lecture partielle est rapide (< 1s pour un √©chantillon d‚Äô1M lignes).  

**Pourquoi :**  
- Le Parquet est optimis√© pour l‚Äôanalytique et r√©duit l‚Äôespace disque.  
- Le partitionnement permet de charger uniquement les donn√©es d‚Äôun patch sans tout lire.  

**Comment :**  
1. Utiliser `df.write_parquet("data/processed/", partition_by=["patch", "date"])`.  
2. V√©rifier la taille du fichier et le temps de lecture avec `time.time()`.  
3. √âcrire un test qui charge uniquement un patch donn√© et mesure le temps.  

**Crit√®res d‚Äôacceptation :**  
- Lecture d‚Äôun seul patch en < 1s sur dataset d‚Äô1M lignes.  
- Donn√©es identiques avant/apr√®s sauvegarde (v√©rif hash).  

**Livrables :**  
- `etl/store.py`  
- `tests/test_store.py`  

**D√©pendances :** TFT-ING-3  

---

## üì¶ R√©sultat attendu de l'EPIC 1

- Un sch√©ma de donn√©es clair et valid√© (`docs/schema.md`)  
- Un import fiable en **Polars** avec validation automatique  
- Des colonnes normalis√©es : `patch`, `stage`, `round_idx`  
- Un stockage rapide en Parquet, pr√™t pour la suite du projet
